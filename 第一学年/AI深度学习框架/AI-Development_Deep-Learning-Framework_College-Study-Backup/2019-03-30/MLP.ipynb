{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train_image,y_train_label),(x_test_image,y_test_label)=mnist.load_data()\n",
    "x_train=x_train_image.reshape(60000,784).astype('float32')\n",
    "x_test=x_test_image.reshape(10000,784).astype('float32')\n",
    "x_train_normalize=x_train/255\n",
    "x_test_normalize=x_test/255\n",
    "y_train_ohe=np_utils.to_categorical(y_train_label)\n",
    "y_test_ohe=np_utils.to_categorical(y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=256,input_dim=784,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(units=10,kernel_initializer='normal',activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "train_history=model.fit(x=x_train_normalize,y=y_train_ohe,validation_split=0.2,epochs=8,batch_size=200,verbose=2)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train(train_history,train,validation):\n",
    "    plot.plot(train_history.history[train])\n",
    "    plot.plot(train_history.history[validation])\n",
    "    plot.show()\n",
    "show_train(train_history,'acc','val_acc')\n",
    "show_train(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result=model.evaluate(x_test_normalize,y_test_ohe)\n",
    "print('acc=',result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # units_list=[2,4,8,16,32,64,128,256,512,1024,2048,4096,8192]\n",
    "# def fit_run(super_model):\n",
    "#     best_acc_num_all=0\n",
    "#     if super_model['layer']:\n",
    "#         units_list=[512,1024,2048]\n",
    "#     else:\n",
    "#         units_list=[512,1024,2048]\n",
    "#     for units in units_list:\n",
    "#         model=Sequential()\n",
    "#         model.compile(loss=super_model['loss'],optimizer=super_model['optimizer'],metrics=['accuracy'])\n",
    "#         if super_model['layer']:\n",
    "#             model.add(Dense(units=super_model['layer'][0],input_dim=784,kernel_initializer='normal',activation='relu'))\n",
    "#             for super_units in super_model['layer'][1:]:\n",
    "#                 model.add(Dense(units=super_units,kernel_initializer='normal',activation='relu'))\n",
    "#             model.add(Dense(units=units,kernel_initializer='normal',activation='relu'))\n",
    "#         else:\n",
    "#             model.add(Dense(units=units,input_dim=784,kernel_initializer='normal',activation='relu'))\n",
    "#         model.add(Dense(units=10,kernel_initializer='normal',activation='softmax'))\n",
    "#         epochs=int(8388608/model.count_params())\n",
    "#         if epochs>=8:\n",
    "#             epochs=8\n",
    "#         if model.count_params()<8388608:\n",
    "#             train_history=model.fit(x=x_train_normalize,y=y_train_ohe,validation_split=0.2,epochs=epochs,batch_size=256,verbose=0)\n",
    "#             best_acc_num=max(train_history.history['val_acc'])\n",
    "#             print(super_model['optimizer']+'\\t'+super_model['loss']+'\\t'+str(super_model['layer']+[units])+'\\t'+str(best_acc_num))\n",
    "#             result_file.write(super_model['optimizer']+'\\t'+super_model['loss']+'\\t'+str(super_model['layer']+[units])+'\\t'+str(best_acc_num)+'\\n')\n",
    "#             del train_history\n",
    "#             if best_acc_num-super_model['acc']>0.05 or (best_acc_num-super_model['acc']>0.005 and best_acc_num>0.9) or (best_acc_num>super_model['acc'] and best_acc_num>0.99):\n",
    "#                 best_acc_num_all=best_acc_num\n",
    "#             else:\n",
    "#                 break\n",
    "#             if (best_acc_num-super_model['acc']>0.05 or (best_acc_num-super_model['acc']>0.005 and best_acc_num>0.9) or (best_acc_num>super_model['acc'] and best_acc_num>0.99)) and len(super_model['layer'])<1:\n",
    "#                 model={\n",
    "#                     'optimizer':super_model['optimizer'],\n",
    "#                     'loss':super_model['loss'],\n",
    "#                     'layer':super_model['layer']+[units],\n",
    "#                     'acc':best_acc_num\n",
    "#                 }\n",
    "#                 fit_run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses=['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error','mean_squared_logarithmic_error','squared_hinge','hinge','categorical_hinge','logcosh','categorical_crossentropy','sparse_categorical_crossentropy','binary_crossentropy','kullback_leibler_divergence','poisson','cosine_proximity']\n",
    "metrics=['acc','binary_accuracy','categorical_accuracy','sparse_categorical_accuracy','top_k_categorical_accuracy','sparse_top_k_categorical_accuracy']\n",
    "optimizers=['sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam']\n",
    "activations=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','exponential','linear']\n",
    "\n",
    "# losses_blacklist=['sparse_categorical_crossentropy']\n",
    "# losses=list(set(losses)-set(losses_blacklist))\n",
    "losses=['categorical_hinge','poisson','categorical_crossentropy','binary_crossentropy','kullback_leibler_divergence']\n",
    "# metrics_blacklist=['sparse_categorical_accuracy','sparse_top_k_categorical_accuracy']\n",
    "# metrics=list(set(metrics)-set(metrics_blacklist))\n",
    "# optimizers_blacklist=['sgd']\n",
    "# optimizers=list(set(optimizers)-set(optimizers_blacklist))\n",
    "# activations_blacklist=['elu','selu','relu','exponential','linear']\n",
    "# activations=list(set(activations)-set(activations_blacklist))\n",
    "\n",
    "metrics=['acc','binary_accuracy','categorical_accuracy','top_k_categorical_accuracy']\n",
    "optimizers=['rmsprop','adagrad','adadelta','adam','adamax','nadam']\n",
    "activations=['softmax','softplus','softsign','tanh','sigmoid','hard_sigmoid']\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "possibility=reduce(lambda x, y: [i+j for i in x for j in y], map(lambda x:[[i] for i in x],[losses,metrics,optimizers,activations,['sigmoid','softmax','softplus']]))\n",
    "# possibility=reduce(lambda x, y: [i+j for i in x for j in y], map(lambda x:[[i] for i in x],[losses,optimizers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# # optimizers=['Nadam']\n",
    "# # losses=['binary_crossentropy']\n",
    "# # for optimizer in optimizers:\n",
    "# #     for loss in losses:\n",
    "# #         model={\n",
    "# #             'optimizer':optimizer,\n",
    "# #             'loss':loss,\n",
    "# #             'layer':[],\n",
    "# #             'acc':0.95\n",
    "# #         }\n",
    "# #         fit_run(model)\n",
    "# num=len(open('result.csv','r').readlines())+1\n",
    "# result_file=open('result.csv','a')\n",
    "# for index in range(len(possibility)-num+1):\n",
    "#     item=possibility[num+index]\n",
    "#     print(num,'/',len(possibility))\n",
    "#     print(item)\n",
    "#     (x_train_image,y_train_label),(x_test_image,y_test_label)=mnist.load_data()\n",
    "#     x_train=x_train_image.reshape(60000,784).astype('float32')\n",
    "#     x_test=x_test_image.reshape(10000,784).astype('float32')\n",
    "#     x_train_normalize=x_train/255\n",
    "#     y_train_ohe=np_utils.to_categorical(y_train_label)\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(units=1024,input_dim=784,kernel_initializer='normal',activation=item[3]))\n",
    "#     model.add(Dense(units=10,kernel_initializer='normal',activation=item[4]))\n",
    "#     model.compile(loss=item[0],optimizer=item[2],metrics=[item[1]])\n",
    "# #     model.add(Dense(units=1024,input_dim=784,kernel_initializer='normal',activation='relu'))\n",
    "# #     model.add(Dense(units=10,kernel_initializer='normal',activation='softmax'))\n",
    "# #     model.compile(loss=item[0],optimizer=item[1],metrics=['acc'])\n",
    "#     train_history=model.fit(x=x_train_normalize,y=y_train_ohe,validation_split=0.2,epochs=8,batch_size=100,verbose=2)\n",
    "#     best_acc_num=max(train_history.history['val_'+item[1]])\n",
    "#     result=model.predict_classes(x_test,verbose=2).astype(int) \n",
    "#     true_acc=0\n",
    "#     for index in range(len(result)):\n",
    "#         if result[index]==y_test_label[index]:\n",
    "#             true_acc+=1\n",
    "#     true_acc/=len(result)\n",
    "#     print(str(item)[1:-1]+'\\t'+str(best_acc_num)+'\\t'+str(true_acc))\n",
    "#     result_file.write(str(item)[1:-1]+','+str(best_acc_num)+','+str(true_acc)+'\\n')\n",
    "#     del model\n",
    "#     clear_output(wait=True)\n",
    "#     num+=1\n",
    "# result_file.close()\n",
    "# print('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=512,input_dim=784,kernel_initializer='normal',activation='tanh'))\n",
    "# model.add(Dense(units=1024,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(units=10,kernel_initializer='normal',activation='softmax'))\n",
    "model.compile(loss='poisson',optimizer='rmsprop',metrics=['categorical_accuracy'])\n",
    "train_history=model.fit(x=x_train_normalize,y=y_train_ohe,validation_split=0.2,epochs=128,batch_size=50,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9536/10000 [===========================>..] - ETA: 0sacc= 0.9834\n",
      "real:->\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t\n",
      "0\t970\t0\t5\t0\t2\t3\t6\t2\t2\t2\t\n",
      "1\t1\t1128\t0\t0\t1\t1\t2\t2\t1\t3\t\n",
      "2\t1\t2\t1011\t5\t3\t1\t1\t7\t2\t0\t\n",
      "3\t0\t0\t2\t991\t0\t9\t0\t2\t6\t3\t\n",
      "4\t1\t0\t1\t0\t962\t0\t1\t1\t4\t5\t\n",
      "5\t2\t1\t0\t1\t0\t861\t4\t0\t2\t3\t\n",
      "6\t3\t2\t2\t0\t3\t7\t942\t0\t0\t2\t\n",
      "7\t1\t1\t6\t2\t0\t1\t0\t1007\t3\t4\t\n",
      "8\t1\t1\t5\t6\t0\t5\t2\t4\t952\t1\t\n",
      "9\t0\t0\t0\t4\t11\t3\t0\t3\t2\t986\t\n",
      "miss\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t\n",
      "0.981\n"
     ]
    }
   ],
   "source": [
    "result=model.evaluate(x_test_normalize,y_test_ohe)\n",
    "print('acc=',result[1])\n",
    "result=np.rint(model.predict(x_test))\n",
    "# result=model.predict(x_test_normalize)\n",
    "# result=np.rint(result).astype(int)\n",
    "result_list=np.zeros((11,10)).astype(int)\n",
    "for index in range(len(result)):\n",
    "    result_list[y_test_label[index]]=result_list[y_test_label[index]]+result[index]\n",
    "    if sum(result[index])==0:\n",
    "        result_list[10][y_test_label[index]]+=1\n",
    "print('real:->\\t',end='')\n",
    "for x in range(10):\n",
    "    print(str(x)+'\\t',end='')\n",
    "print()\n",
    "for y in range(10):\n",
    "    print(str(y)+'\\t',end='')\n",
    "    for x in range(10):\n",
    "        print(str(result_list[x][y])+'\\t',end='')\n",
    "    print()\n",
    "print('miss\\t',end='')\n",
    "for x in range(10):\n",
    "    print(str(result_list[10][x])+'\\t',end='')\n",
    "print()\n",
    "n=0\n",
    "for x in range(10):\n",
    "    n+=result_list[x][x]\n",
    "print(n/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s\n",
      "[7 2 1 ..., 4 5 6] 0.9811\n"
     ]
    }
   ],
   "source": [
    "result=model.predict_classes(x_test).astype(int) \n",
    "true_acc=0\n",
    "for index in range(len(result)):\n",
    "    if result[index]==y_test_label[index]:\n",
    "        true_acc+=1\n",
    "true_acc/=len(result)\n",
    "print()\n",
    "print(result,true_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9888/10000 [============================>.] - ETA: 0s\n",
      "[-1.4506213441200088e-05, 0.99980000000000002]\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=512,input_dim=784,kernel_initializer='normal',activation='softplus'))\n",
    "# model.add(Dense(units=1024,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(units=10,kernel_initializer='normal',activation='sigmoid'))\n",
    "model.compile(loss='kullback_leibler_divergence',optimizer='rmsprop',metrics=['top_k_categorical_accuracy'])\n",
    "train_history=model.fit(x=x_train_normalize,y=y_train_ohe,validation_split=0.2,epochs=16,batch_size=50,verbose=0)\n",
    "result=model.evaluate(x_test_normalize,y_test_ohe)\n",
    "print()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
